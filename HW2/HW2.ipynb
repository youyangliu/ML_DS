{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------import libraries-------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import hstack, csr_matrix, diags\n",
    "from scipy.stats import itemfreq\n",
    "from nltk.stem import PorterStemmer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------load data-------------------------------\n",
    "data = pd.read_csv(\"reviews_tr.csv\")\n",
    "data = shuffle(data,random_state=0, n_samples = int(len(data)/2))\n",
    "test_data = pd.read_csv(\"reviews_te.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------build online perceptron function-------------------------------\n",
    "def online_perceptron(train_data, train_label):\n",
    "    '''\n",
    "    set parameters\n",
    "    train_data: scipy sparse matrix, feature matrix that contains processed frequency counts of\n",
    "                input texts.\n",
    "    train_label: np.array, corresponding traning labels\n",
    "    '''\n",
    "    w=np.zeros((np.shape(train_data)[1],1))\n",
    "\n",
    "    random.seed(0)\n",
    "    #shuffle training data between each pass\n",
    "    sel = random.sample(range(len(train_label)),len(train_label))\n",
    "    train_s = train_data[sel]\n",
    "    labels_s = train_label[sel]\n",
    "\n",
    "    for i in range(0,len(train_label)):\n",
    "        y_t = labels_s[i]\n",
    "        x_t = train_s[i,:]\n",
    "        if y_t*(x_t.dot(w))<= 0:\n",
    "            w = w + y_t*x_t.transpose()\n",
    "    \n",
    "    #shuffle training data between each pass\n",
    "    sel = random.sample(range(len(train_label)),len(train_label))\n",
    "    train_s = train_data[sel]\n",
    "    labels_s = train_label[sel]\n",
    "\n",
    "    w_f = w\n",
    "    count =1\n",
    "\n",
    "    for j in range(0,len(train_label)):\n",
    "        y_t = labels_s[j]\n",
    "        x_t = train_s[j,:]\n",
    "        if y_t*(x_t.dot(w)) <= 0:\n",
    "            w = w + y_t*x_t.transpose()\n",
    "        w_f += w\n",
    "        count += 1\n",
    "\n",
    "    w_final = (1/(len(train_label)+1))*w_f\n",
    "    \n",
    "    return w_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------------------------------build evaluate function-------------------------------\n",
    "def evaluate(data_name, coef, train_data, train_label, test_data, test_label):\n",
    "    '''\n",
    "    set parameters\n",
    "    data_name: data representation name\n",
    "    coef: numpy column vector returned by online_perception function\n",
    "    train_data: scipy sparse matrix, feature matrix that contains processed frequency counts of\n",
    "                training texts.\n",
    "    train_label: numpy column vector, corresponding traning labels\n",
    "    test_data: scipy sparse matrix, feature matrix that contains processed frequency counts of\n",
    "               testing texts.\n",
    "    test_label: numpy column vector, corresponding test labels\n",
    "    '''\n",
    "    y_hat_tr = train_data.dot(coef)\n",
    "    np.place(y_hat_tr, y_hat_tr <= 0, -1)\n",
    "    np.place(y_hat_tr, y_hat_tr > 0, 1)\n",
    "    tr_error = 1-sum(y_hat_tr == train_label)/len(train_label)\n",
    "    \n",
    "    y_hat_te = test_data.dot(coef)\n",
    "    np.place(y_hat_te, y_hat_te <= 0, -1)\n",
    "    np.place(y_hat_te, y_hat_te > 0, 1)\n",
    "    te_error = 1-sum(y_hat_te == test_label)/len(test_label)\n",
    "    \n",
    "    print (data_name,\"\\n\"\n",
    "       \"Training error: \", tr_error, \"\\n\"\n",
    "       \"Testing error: \", te_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate unigram representation, including words consisting of only 1 character\n",
    "uni_vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "uni = uni_vectorizer.fit_transform(data['text'])\n",
    "#add intercept\n",
    "inter_tr = csr_matrix(np.ones((np.shape(uni)[0],1)))\n",
    "uni = hstack([inter_tr,uni],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace 0 values in the label with -1\n",
    "uni_labels = np.array(data['label'])\n",
    "np.place(uni_labels, uni_labels==0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform test data to unigram representation\n",
    "uni_test = uni_vectorizer.transform(test_data['text'])\n",
    "inter_te = csr_matrix(np.ones((np.shape(uni_test)[0],1)))\n",
    "uni_test = hstack([inter_te,uni_test],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram \n",
      "Training error:  [[ 0.102064]] \n",
      "Testing error:  [[ 0.10706856]]\n",
      "CPU times: user 6min 10s, sys: 7.76 s, total: 6min 18s\n",
      "Wall time: 6min 42s\n"
     ]
    }
   ],
   "source": [
    "#reshape label arrays for later use\n",
    "train_labels = uni_labels.reshape((len(uni_labels),1))\n",
    "test_labels = test_data['label'].values.reshape((np.shape(uni_test)[0],1))\n",
    "np.place(test_labels, test_labels==0, -1)\n",
    "\n",
    "#implement online perceptron algorithm on the unigram representation\n",
    "uni_coef = online_perceptron(uni, uni_labels)\n",
    "#evaluate results\n",
    "evaluate(\"Unigram\", uni_coef, uni, train_labels, uni_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappoint :  155.33614132771734\n",
      "fantastic :  114.51875296249408\n",
      "gem :  124.1740016519967\n",
      "glad :  112.33664932670135\n",
      "heaven :  125.48762902474195\n",
      "incredible :  136.38361923276153\n",
      "perfect :  115.48232703534593\n",
      "perfection :  141.20899958200084\n",
      "perfectly :  114.98477403045194\n",
      "phenomenal :  117.36258327483345\n"
     ]
    }
   ],
   "source": [
    "#find top 10 words with highest weights\n",
    "uni_coef_r = uni_coef[1:].reshape((1,len(uni_coef)-1)).tolist()[0]\n",
    "\n",
    "def f(a,N,ord):\n",
    "    return np.argsort(a)[::ord][:N]\n",
    "\n",
    "high_w = {}\n",
    "for i in f(uni_coef_r, 10,-1):\n",
    "    high_w[uni_vectorizer.get_feature_names()[i]]=uni_coef_r[i]\n",
    "\n",
    "for k in sorted(high_w):\n",
    "    print(k,\": \", high_w[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bland :  -143.502196995606\n",
      "disappointing :  -143.86230627538745\n",
      "disappointment :  -139.06741386517228\n",
      "flavorless :  -141.94608810782378\n",
      "horrible :  -154.06152987694026\n",
      "lacked :  -154.84012031975936\n",
      "mediocre :  -190.95191209617582\n",
      "meh :  -161.6284927430145\n",
      "tasteless :  -145.63292473415052\n",
      "worst :  -209.02757794484413\n"
     ]
    }
   ],
   "source": [
    "#find top 10 words with lowest weights\n",
    "low_w = {}\n",
    "for i in f(uni_coef_r, 10,1):\n",
    "    low_w[uni_vectorizer.get_feature_names()[i]]=uni_coef_r[i]\n",
    "\n",
    "for k in sorted(low_w):\n",
    "    print(k,\": \", low_w[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate bigram representation, including words consisting of only 1 character\n",
    "bi_vectorizer = CountVectorizer(ngram_range=(2,2),token_pattern=r'\\b\\w+\\b')\n",
    "bi = bi_vectorizer.fit_transform(data['text'])\n",
    "#add intercept\n",
    "inter_tr = csr_matrix(np.ones((np.shape(bi)[0],1)))\n",
    "bi = hstack([inter_tr,bi],format='csr')\n",
    "\n",
    "#tranform test data into bigram representation\n",
    "bi_test = bi_vectorizer.transform(test_data['text'])\n",
    "inter_te = csr_matrix(np.ones((np.shape(bi_test)[0],1)))\n",
    "bi_test = hstack([inter_te,bi_test],format='csr')\n",
    "\n",
    "#replace 0 values in the label with -1\n",
    "bi_labels = np.array(data['label'])\n",
    "np.place(bi_labels, bi_labels==0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#reshape label arrays for later use\n",
    "train_labels = bi_labels.reshape((len(bi_labels),1))\n",
    "test_labels = test_data['label'].values.reshape((np.shape(bi_test)[0],1))\n",
    "np.place(test_labels, test_labels==0, -1)\n",
    "\n",
    "#implement online percpetron algorithm on bigram representation\n",
    "bi_coef = online_perceptron(bi, bi_labels)\n",
    "#evaluate results\n",
    "evaluate(\"Bigram\", bi_coef, bi, train_labels, bi_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram \n",
      "Training error:  [[ 0.050946]] \n",
      "Testing error:  [[ 0.10681553]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(\"Bigram\", bi_coef, bi, train_labels, bi_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate term frequency representation, including words consisting of only 1 character\n",
    "tf_vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "tf = tf_vectorizer.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate df\n",
    "word_count_by_col = itemfreq(tf.nonzero()[1]).transpose()\n",
    "#calculate idf\n",
    "log_idf = np.log10(np.shape(tf)[0]/(word_count_by_col[1]))\n",
    "idf_mtx = diags(log_idf, 0)\n",
    "#calculate tf-idf\n",
    "tfidf=tf.dot(idf_mtx)\n",
    "\n",
    "#add intercept\n",
    "inter_tr = csr_matrix(np.ones((np.shape(tfidf)[0],1)))\n",
    "tfidf = hstack([inter_tr,tfidf],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform test data into term frequency representation\n",
    "tf_test = tf_vectorizer.transform(test_data['text'])\n",
    "#calculate tf-idf on test data\n",
    "tfidf_test=tf_test.dot(idf_mtx)\n",
    "\n",
    "#add intercept\n",
    "inter_te = csr_matrix(np.ones((np.shape(tfidf_test)[0],1)))\n",
    "tfidf_test = hstack([inter_te,tfidf_test],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-idf \n",
      "Training error:  [[ 0.090786]] \n",
      "Testing error:  [[ 0.11401278]]\n",
      "CPU times: user 5min 46s, sys: 8.57 s, total: 5min 55s\n",
      "Wall time: 6min 30s\n"
     ]
    }
   ],
   "source": [
    "#replace 0 values in the label with -1\n",
    "tfidf_labels = np.array(data['label'])\n",
    "np.place(tfidf_labels, tfidf_labels==0, -1)\n",
    "\n",
    "#implement online perceptron algorithm on tf-idf representation\n",
    "tfidf_coef = online_perceptron(tfidf, tfidf_labels)\n",
    "#evaluate results\n",
    "evaluate(\"Tf-idf\", tfidf_coef, tfidf, train_labels, tfidf_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stemming + Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define stemming function\n",
    "def pstem(row):\n",
    "    '''\n",
    "    row: takes a row from a dataframe\n",
    "    '''\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    stem=\"\"\n",
    "    for w in (row['text'].split()):\n",
    "        stem=' '.join((stem,ps.stem(w)))\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new column on training data containing stemmed text using pstem function\n",
    "data['stemmed_text']=data.apply(lambda row: pstem(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data for repeated use\n",
    "data.to_csv(\"reviews_tr_50_stemmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 20s, sys: 7.02 s, total: 14min 27s\n",
      "Wall time: 14min 54s\n"
     ]
    }
   ],
   "source": [
    "#create a new column on test data containing stemmed text using pstem function\n",
    "test_data['stemmed_text']=test_data.apply(lambda row: pstem(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save test data for repeated use\n",
    "test_data.to_csv(\"reviews_te_stemmed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate unigram representation on stemmed text, including words consisting of only 1 character\n",
    "stm_vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "stm = stm_vectorizer.fit_transform(data['stemmed_text'])\n",
    "#add intercept\n",
    "inter_tr = csr_matrix(np.ones((np.shape(stm)[0],1)))\n",
    "stm = hstack([inter_tr,stm],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace 0 values in the label with -1\n",
    "stm_labels = np.array(data['label'])\n",
    "np.place(stm_labels, stm_labels==0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tranform stemmed test data into unigram representation\n",
    "stm_test = stm_vectorizer.transform(test_data['stemmed_text'])\n",
    "inter_te = csr_matrix(np.ones((np.shape(stm_test)[0],1)))\n",
    "stm_test = hstack([inter_te,stm_test],format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming + Unigram \n",
      "Training error:  [[ 0.105082]] \n",
      "Testing error:  [[ 0.10929583]]\n",
      "CPU times: user 5min 3s, sys: 9.35 s, total: 5min 13s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "#reshape label arrays for later use\n",
    "train_labels = stm_labels.reshape((len(stm_labels),1))\n",
    "test_labels = test_data['label'].values.reshape((np.shape(stm_test)[0],1))\n",
    "np.place(test_labels, test_labels==0, -1)\n",
    "\n",
    "#implememnt online perceptron algorithm on stemming + unigram representation\n",
    "stm_coef = online_perceptron(stm, stm_labels)\n",
    "#evaluate results\n",
    "evaluate(\"Stemming + Unigram\", stm_coef, stm, train_labels, stm_test, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
